{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and data importing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.statespace.structural import UnobservedComponents\n",
    "from statsmodels.tsa.exponential_smoothing.ets import ETSModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, root_mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributor</th>\n",
       "      <th>category</th>\n",
       "      <th>repository</th>\n",
       "      <th>activity</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AmplabJenkins</td>\n",
       "      <td>bot</td>\n",
       "      <td>apache/spark</td>\n",
       "      <td>Commenting pull request</td>\n",
       "      <td>2022-11-25 09:55:19+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AmplabJenkins</td>\n",
       "      <td>bot</td>\n",
       "      <td>apache/spark</td>\n",
       "      <td>Commenting pull request</td>\n",
       "      <td>2022-11-25 09:55:23+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AmplabJenkins</td>\n",
       "      <td>bot</td>\n",
       "      <td>apache/spark</td>\n",
       "      <td>Commenting pull request</td>\n",
       "      <td>2022-11-25 09:55:26+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>analysis-bot</td>\n",
       "      <td>bot</td>\n",
       "      <td>facebook/react-native</td>\n",
       "      <td>Commenting pull request</td>\n",
       "      <td>2022-11-25 09:55:27+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neos-bot</td>\n",
       "      <td>bot</td>\n",
       "      <td>neos/neos-ui-compiled</td>\n",
       "      <td>Pushing commits</td>\n",
       "      <td>2022-11-25 09:55:47+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015418</th>\n",
       "      <td>798388</td>\n",
       "      <td>human</td>\n",
       "      <td>879434</td>\n",
       "      <td>Reviewing code</td>\n",
       "      <td>2023-04-15 16:06:15+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015419</th>\n",
       "      <td>798388</td>\n",
       "      <td>human</td>\n",
       "      <td>879434</td>\n",
       "      <td>Reviewing code</td>\n",
       "      <td>2023-04-15 16:07:26+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015420</th>\n",
       "      <td>784775</td>\n",
       "      <td>human</td>\n",
       "      <td>643744</td>\n",
       "      <td>Creating branch</td>\n",
       "      <td>2023-04-15 16:07:33+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015421</th>\n",
       "      <td>784775</td>\n",
       "      <td>human</td>\n",
       "      <td>888378</td>\n",
       "      <td>Opening pull request</td>\n",
       "      <td>2023-04-15 16:08:07+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015422</th>\n",
       "      <td>387854</td>\n",
       "      <td>human</td>\n",
       "      <td>956848</td>\n",
       "      <td>Forking repository</td>\n",
       "      <td>2023-04-15 16:14:22+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1015423 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           contributor category             repository  \\\n",
       "0        AmplabJenkins      bot           apache/spark   \n",
       "1        AmplabJenkins      bot           apache/spark   \n",
       "2        AmplabJenkins      bot           apache/spark   \n",
       "3         analysis-bot      bot  facebook/react-native   \n",
       "4             neos-bot      bot  neos/neos-ui-compiled   \n",
       "...                ...      ...                    ...   \n",
       "1015418         798388    human                 879434   \n",
       "1015419         798388    human                 879434   \n",
       "1015420         784775    human                 643744   \n",
       "1015421         784775    human                 888378   \n",
       "1015422         387854    human                 956848   \n",
       "\n",
       "                        activity                      date  \n",
       "0        Commenting pull request 2022-11-25 09:55:19+00:00  \n",
       "1        Commenting pull request 2022-11-25 09:55:23+00:00  \n",
       "2        Commenting pull request 2022-11-25 09:55:26+00:00  \n",
       "3        Commenting pull request 2022-11-25 09:55:27+00:00  \n",
       "4                Pushing commits 2022-11-25 09:55:47+00:00  \n",
       "...                          ...                       ...  \n",
       "1015418           Reviewing code 2023-04-15 16:06:15+00:00  \n",
       "1015419           Reviewing code 2023-04-15 16:07:26+00:00  \n",
       "1015420          Creating branch 2023-04-15 16:07:33+00:00  \n",
       "1015421     Opening pull request 2023-04-15 16:08:07+00:00  \n",
       "1015422       Forking repository 2023-04-15 16:14:22+00:00  \n",
       "\n",
       "[1015423 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activities = pd.read_parquet('../data-raw/activities.parquet')\n",
    "activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "600 events at max for each contributor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributor</th>\n",
       "      <th>category</th>\n",
       "      <th>repository</th>\n",
       "      <th>activity</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>nodebb-misty</td>\n",
       "      <td>bot</td>\n",
       "      <td>julianlam/nodebb-plugin-email-helper</td>\n",
       "      <td>Closing pull request</td>\n",
       "      <td>2022-11-25 11:08:46+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>nodebb-misty</td>\n",
       "      <td>bot</td>\n",
       "      <td>NodeBB/nodebb-plugin-topic-redirect</td>\n",
       "      <td>Closing pull request</td>\n",
       "      <td>2022-11-25 11:20:10+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>nodebb-misty</td>\n",
       "      <td>bot</td>\n",
       "      <td>NodeBB/nodebb-plugin-write-api</td>\n",
       "      <td>Closing pull request</td>\n",
       "      <td>2022-11-25 11:21:23+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>nodebb-misty</td>\n",
       "      <td>bot</td>\n",
       "      <td>julianlam/nodebb-plugin-sso-oauth</td>\n",
       "      <td>Closing pull request</td>\n",
       "      <td>2022-11-25 11:47:30+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5518</th>\n",
       "      <td>jenkins-x-bot-test</td>\n",
       "      <td>bot</td>\n",
       "      <td>jenkins-x-charts/jxboot-helmfile-resources</td>\n",
       "      <td>Creating branch</td>\n",
       "      <td>2022-11-26 19:57:10+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015418</th>\n",
       "      <td>798388</td>\n",
       "      <td>human</td>\n",
       "      <td>879434</td>\n",
       "      <td>Reviewing code</td>\n",
       "      <td>2023-04-15 16:06:15+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015419</th>\n",
       "      <td>798388</td>\n",
       "      <td>human</td>\n",
       "      <td>879434</td>\n",
       "      <td>Reviewing code</td>\n",
       "      <td>2023-04-15 16:07:26+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015420</th>\n",
       "      <td>784775</td>\n",
       "      <td>human</td>\n",
       "      <td>643744</td>\n",
       "      <td>Creating branch</td>\n",
       "      <td>2023-04-15 16:07:33+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015421</th>\n",
       "      <td>784775</td>\n",
       "      <td>human</td>\n",
       "      <td>888378</td>\n",
       "      <td>Opening pull request</td>\n",
       "      <td>2023-04-15 16:08:07+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015422</th>\n",
       "      <td>387854</td>\n",
       "      <td>human</td>\n",
       "      <td>956848</td>\n",
       "      <td>Forking repository</td>\n",
       "      <td>2023-04-15 16:14:22+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                contributor category  \\\n",
       "365            nodebb-misty      bot   \n",
       "409            nodebb-misty      bot   \n",
       "417            nodebb-misty      bot   \n",
       "523            nodebb-misty      bot   \n",
       "5518     jenkins-x-bot-test      bot   \n",
       "...                     ...      ...   \n",
       "1015418              798388    human   \n",
       "1015419              798388    human   \n",
       "1015420              784775    human   \n",
       "1015421              784775    human   \n",
       "1015422              387854    human   \n",
       "\n",
       "                                         repository              activity  \\\n",
       "365            julianlam/nodebb-plugin-email-helper  Closing pull request   \n",
       "409             NodeBB/nodebb-plugin-topic-redirect  Closing pull request   \n",
       "417                  NodeBB/nodebb-plugin-write-api  Closing pull request   \n",
       "523               julianlam/nodebb-plugin-sso-oauth  Closing pull request   \n",
       "5518     jenkins-x-charts/jxboot-helmfile-resources       Creating branch   \n",
       "...                                             ...                   ...   \n",
       "1015418                                      879434        Reviewing code   \n",
       "1015419                                      879434        Reviewing code   \n",
       "1015420                                      643744       Creating branch   \n",
       "1015421                                      888378  Opening pull request   \n",
       "1015422                                      956848    Forking repository   \n",
       "\n",
       "                             date  \n",
       "365     2022-11-25 11:08:46+00:00  \n",
       "409     2022-11-25 11:20:10+00:00  \n",
       "417     2022-11-25 11:21:23+00:00  \n",
       "523     2022-11-25 11:47:30+00:00  \n",
       "5518    2022-11-26 19:57:10+00:00  \n",
       "...                           ...  \n",
       "1015418 2023-04-15 16:06:15+00:00  \n",
       "1015419 2023-04-15 16:07:26+00:00  \n",
       "1015420 2023-04-15 16:07:33+00:00  \n",
       "1015421 2023-04-15 16:08:07+00:00  \n",
       "1015422 2023-04-15 16:14:22+00:00  \n",
       "\n",
       "[162000 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ( \n",
    "    activities\n",
    "    # keep the last 600 events for each contributor\n",
    "    .groupby('contributor')\n",
    "    .tail(600)\n",
    "    # keep the contributors who have more than 600 events\n",
    "    .groupby('contributor')\n",
    "    .filter(lambda x: len(x) >= 600)\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gap_activities(train, test):\n",
    "\n",
    "    start_time = train['date'].iloc[-1] + pd.Timedelta(hours=1)\n",
    "    end_time = test['date'].iloc[0] - pd.Timedelta(hours=1)\n",
    "\n",
    "    #  check if there is a time gap between the train and test data\n",
    "    if end_time - start_time >= pd.Timedelta(hours=0):\n",
    "\n",
    "        # fill the gap with a date range and zeros for n_activities\n",
    "        gap_data = pd.DataFrame({\n",
    "            'category': train['category'].iloc[0],\n",
    "            'date': pd.date_range(start=start_time, end=end_time, freq='H'),\n",
    "            'contributor': train['contributor'].iloc[0],\n",
    "            'n_activities': 0\n",
    "        })\n",
    "\n",
    "        test = pd.concat([gap_data, test]).reset_index(drop=True)\n",
    "    \n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_activities(contributor):\n",
    "\n",
    "    # spliting the data into training and testing sets for time series forecasting, using a time-based split with split size = 0.5\n",
    "    train, test = (\n",
    "        contributor\n",
    "        .apply(lambda x: x[:300])\n",
    "        .groupby(['category', pd.Grouper(key='date', freq='H'), 'contributor'])['activity']\n",
    "        .count()\n",
    "        .reset_index(name='n_activities'),\n",
    "\n",
    "        contributor\n",
    "        .apply(lambda x: x[300:])\n",
    "        .groupby(['category', pd.Grouper(key='date', freq='H'), 'contributor'])['activity']\n",
    "        .count()\n",
    "        .reset_index(name='n_activities')\n",
    "    )\n",
    "\n",
    "    # checking if the last timestamp of the train data is equal to the first timestamp of the second data\n",
    "    if train['date'].iloc[-1] == test['date'].iloc[0]:\n",
    "        # adding the value of the last time value (n_activities) of train data to the value of the first time (n_activities) of the test data\n",
    "        test.loc[0, 'n_activities'] += train.loc[train.index[-1], 'n_activities']\n",
    "        # removing the last time of the train data\n",
    "        train.drop(train.index[-1], inplace=True)\n",
    "\n",
    "    test = gap_activities(train, test)\n",
    "\n",
    "    # filling n_activities with zeros for the empty hours between the minimum and maximum date\n",
    "    train, test = (\n",
    "        # for train set, we take last 3 months\n",
    "        train[train['date'] >= train['date'].max() - pd.DateOffset(months=3)]\n",
    "        .set_index('date')\n",
    "        .resample('H')\n",
    "        .sum()\n",
    "        .rename_axis(None)\n",
    "        .replace({'category': 0, 'contributor': 0}, None)\n",
    "        .ffill(),\n",
    "        \n",
    "        test\n",
    "        .set_index('date')\n",
    "        .resample('H')\n",
    "        .sum()\n",
    "        .rename_axis(None)\n",
    "        .replace({'category': 0, 'contributor': 0}, None)\n",
    "        .ffill()\n",
    "    )\n",
    "\n",
    "    train.index.freq = 'H'\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New evaluation metrics PGA & CTD?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new evaluation metric that calculates the percentage of predicted values greater than or equal to the actual values. We can define this metric as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$PGA = \\frac{\\sum_{i=1}^{n} [y_i \\leq \\hat{y}_i]}{n}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pga_score(y_true, y_pred):\n",
    "    return (y_pred >= y_true).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A novel evaluation metric designed to quantify the time difference between the cumulative sums of true and predicted values in reaching a specified target value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{CTD} = \\text{argmax}(C_t \\geq T) - \\text{argmax}(C_p \\geq T) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This formula represents the time difference between the cumulative sums of the true $C_t$ and predicted $C_p$ values in reaching a specified target value $T(100, 200, 300)$, where ${argmax}$ returns the time of the first occurrence where the condition is satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctd_score(y_true, y_pred, target_value):\n",
    "\n",
    "    coef = 1\n",
    "    if (sum(y_true) < target_value) | (sum(y_pred) < target_value):\n",
    "        coef = -1\n",
    "\n",
    "    true_cumsum, pred_cumsum = np.cumsum(y_true), np.cumsum(y_pred)\n",
    "    time_true, time_pred = np.argmax(true_cumsum >= target_value), np.argmax(pred_cumsum >= target_value)\n",
    "\n",
    "    return coef*(time_true - time_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Time Difference: -2\n"
     ]
    }
   ],
   "source": [
    "true_values = [2, 11, 84, 57, 0, 38, 15, 80, 4, 30, 90, 0, 0, 600]\n",
    "pred_values = [52, 22, 95, 9, 11, 1, 73, 0, 3, 5, 10, 70, 50, 0]\n",
    "\n",
    "\n",
    "print(\"Cumulative Time Difference:\", ctd_score(true_values, pred_values, 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Autoregressive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ar_model(contributor):\n",
    "\n",
    "    print(contributor['contributor'].iloc[0])\n",
    "\n",
    "    # Spliting the data into training and testing sets\n",
    "    train, test = split_activities(contributor)\n",
    "\n",
    "    # Fit the model\n",
    "    try:\n",
    "        lags = [1, 12, 24, 168]\n",
    "        model = AutoReg(train['n_activities'], lags=lags).fit()\n",
    "        predictions = model.get_prediction(start=len(train), end=len(train)+len(test)-1).summary_frame(alpha=0.05)\n",
    "    except IndexError:\n",
    "        lags = [1, 12, 24]\n",
    "        model = AutoReg(train['n_activities'], lags=lags).fit()\n",
    "        predictions = model.get_prediction(start=len(train), end=len(train)+len(test)-1).summary_frame(alpha=0.05)\n",
    "    except:\n",
    "        lags = int(len(train)/2)-1\n",
    "        model = AutoReg(train['n_activities'], lags=lags).fit()\n",
    "        predictions = model.get_prediction(start=len(train), end=len(train)+len(test)-1).summary_frame(alpha=0.05)\n",
    "\n",
    "    # Create a series for evaluation metrics and sum of activities\n",
    "    metrics = pd.Series({\n",
    "        'contributor': contributor['contributor'].iloc[0],\n",
    "        'category': contributor['category'].iloc[0],\n",
    "        'r2': r2_score(test['n_activities'], predictions['mean']),\n",
    "        'mae': mean_absolute_error(test['n_activities'], predictions['mean']),\n",
    "        'rmse': root_mean_squared_error(test['n_activities'], predictions['mean']),\n",
    "        'pga': pga_score(test['n_activities'], predictions['mean']),\n",
    "        'ctd_100': ctd_score(test['n_activities'], predictions['mean'], 100),\n",
    "        'ctd_200': ctd_score(test['n_activities'], predictions['mean'], 200),\n",
    "        'ctd_300': ctd_score(test['n_activities'], predictions['mean'], 300),\n",
    "        'n_activities': train['n_activities'].sum(),\n",
    "        'lags': lags,\n",
    "        'true_values': test['n_activities'].values,\n",
    "        'predicted_values': predictions['mean'].values,\n",
    "    })\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0crat\n",
      "AppVeyorBot\n",
      "Code-Inside-Bot\n",
      "CrowdinBot\n",
      "DrahtBot\n",
      "PJBot\n",
      "addonsbot\n",
      "adobe-bot\n",
      "agones-bot\n",
      "alluxio-bot\n",
      "analysis-bot\n",
      "angular-automatic-lock-bot[bot]\n",
      "ansibot\n",
      "apmmachine\n",
      "aporeto-bot\n",
      "aws-cdk-automation\n",
      "backportbot-nextcloud[bot]\n",
      "ballerina-bot\n",
      "bedevere-bot\n",
      "bits-bot\n",
      "blathers-crl[bot]\n",
      "bluespice-github-bot\n",
      "boring-cyborg[bot]\n",
      "bors-servo\n",
      "bot-gradle\n",
      "carsonbot\n",
      "cf-gitbot\n",
      "cheminfo-bot\n",
      "cla-bot[bot]\n",
      "cmsdmwmbot\n",
      "codeclimate[bot]\n",
      "codesandbox[bot]\n",
      "confs-tech-bot\n",
      "cozy-bot\n",
      "cypress-bot[bot]\n",
      "delete-merged-branch[bot]\n",
      "devOpsHazelcast\n",
      "dlang-bot\n",
      "docker-library-bot\n",
      "dontcallmedom-bot\n",
      "dotnet-bot\n",
      "dotnet-issue-labeler[bot]\n",
      "dotnet-maestro-bot\n",
      "edx-requirements-bot\n",
      "edx-transifex-bot\n",
      "elife-bot\n",
      "engine-flutter-autoroll\n",
      "fire-bot\n",
      "flinkbot\n",
      "fluttergithubbot\n",
      "forking-renovate[bot]\n",
      "fossabot\n",
      "garybot2\n",
      "gatsby-cloud[bot]\n",
      "getsentry-bot\n",
      "gitguardian[bot]\n",
      "gitpod-io[bot]\n",
      "google-ml-butler[bot]\n",
      "google-oss-bot\n",
      "graalvmbot\n",
      "graviteeio\n",
      "guardrails[bot]\n",
      "hashicorp-cla\n",
      "hasura-bot\n",
      "hft-team-city\n",
      "ibmdotcom-bot\n",
      "ionitron-bot[bot]\n",
      "istio-policy-bot\n",
      "jbosstm-bot\n",
      "jenkins-x-bot-test\n",
      "jetstack-bot\n",
      "jitsi-jenkins\n",
      "johnpbloch-bot\n",
      "jujubot\n",
      "knative-prow-robot\n",
      "ks-ci-bot\n",
      "kubevirt-commenter-bot\n",
      "lgtm-com[bot]\n",
      "lingohub[bot]\n",
      "linux-foundation-easycla[bot]\n",
      "livingdocs-automation\n",
      "mender-test-bot\n",
      "metal3-io-bot\n",
      "metamaskbot\n",
      "minikube-bot\n",
      "minikube-pr-bot\n",
      "minio-trusted\n",
      "miss-islington\n",
      "mister-roboto\n",
      "mm-cloud-bot\n",
      "moz-wptsync-bot\n",
      "mumukibot\n",
      "nacho-bot\n",
      "neos-bot\n",
      "netkan-bot\n",
      "nextcloud-bot\n",
      "ninjadotorg-bot\n",
      "niveristand-diff-bot\n",
      "nodebb-misty\n",
      "nodejs-github-bot\n",
      "nur-bot\n",
      "octokit-fixture-user-a\n",
      "octokitbot\n",
      "oll-bot\n",
      "openhab-bot\n",
      "openshift-cherrypick-robot\n",
      "openssl-machine\n",
      "pantheon-ci-bot\n",
      "pdfjsbot\n",
      "pirate-bot\n",
      "pivotal-cla\n",
      "pytorchbot\n",
      "qmk-bot\n",
      "r-ryantm\n",
      "release-drafter[bot]\n",
      "renovate-approve-2[bot]\n",
      "repo-ranger[bot]\n",
      "restyled-io[bot]\n",
      "review-notebook-app[bot]\n",
      "robot-clickhouse\n",
      "rultor\n",
      "rust-timer\n",
      "rustbot\n",
      "sagemaker-bot\n",
      "salesforce-cla[bot]\n",
      "scrutinizer-notifier\n",
      "sentry-io[bot]\n",
      "similar-code-searcher[bot]\n",
      "skia-flutter-autoroll\n",
      "softwarefactory-project-zuul[bot]\n",
      "soloio-bot\n",
      "sourcegraph-bot\n",
      "spinnakerbot\n",
      "spring-builds\n",
      "sprucelabs-ci\n",
      "sre-bot\n",
      "stakater-user\n",
      "status-im-auto\n",
      "submariner-bot\n",
      "swift-ci\n",
      "taichi-gardener\n",
      "thundernest-bot\n",
      "translatewiki\n",
      "tykbot[bot]\n",
      "usercont-release-bot\n",
      "va-bot\n",
      "vc-ci\n",
      "violinist-bot\n",
      "vmwclabot\n",
      "vscode-issue-tracker-bot\n",
      "vtex-io-ci-cd[bot]\n",
      "vtex-io-docs-bot[bot]\n",
      "welcome[bot]\n",
      "wet-boew-bot\n",
      "wso2-jenkins-bot\n",
      "335498\n",
      "335745\n",
      "353444\n",
      "355383\n",
      "359854\n",
      "364686\n",
      "367939\n",
      "368375\n",
      "373769\n",
      "374774\n",
      "376887\n",
      "377538\n",
      "377543\n",
      "387658\n",
      "387854\n",
      "437693\n",
      "437766\n",
      "438655\n",
      "446498\n",
      "449544\n",
      "449583\n",
      "454496\n",
      "454638\n",
      "455745\n",
      "456995\n",
      "459877\n",
      "465566\n",
      "473965\n",
      "475849\n",
      "483648\n",
      "487355\n",
      "489848\n",
      "535599\n",
      "537443\n",
      "543595\n",
      "549789\n",
      "553976\n",
      "558473\n",
      "567384\n",
      "567396\n",
      "567743\n",
      "576539\n",
      "578794\n",
      "579369\n",
      "587344\n",
      "597849\n",
      "645363\n",
      "646677\n",
      "646795\n",
      "648358\n",
      "656549\n",
      "658766\n",
      "658938\n",
      "664498\n",
      "664693\n",
      "668867\n",
      "669693\n",
      "673338\n",
      "674548\n",
      "689788\n",
      "733774\n",
      "735987\n",
      "743485\n",
      "744346\n",
      "748599\n",
      "754548\n",
      "754564\n",
      "755587\n",
      "757389\n",
      "758333\n",
      "763394\n",
      "767954\n",
      "769343\n",
      "769399\n",
      "773356\n",
      "783656\n",
      "784775\n",
      "787773\n",
      "795565\n",
      "795985\n",
      "797989\n",
      "798388\n",
      "843533\n",
      "845398\n",
      "847775\n",
      "849548\n",
      "859454\n",
      "859754\n",
      "864856\n",
      "864943\n",
      "865858\n",
      "873354\n",
      "885533\n",
      "885899\n",
      "893864\n",
      "896363\n",
      "897436\n",
      "897688\n",
      "933837\n",
      "946773\n",
      "947579\n",
      "949698\n",
      "954443\n",
      "955787\n",
      "957953\n",
      "966834\n",
      "976375\n",
      "977484\n",
      "978678\n",
      "979384\n",
      "983548\n",
      "983874\n",
      "985588\n",
      "987894\n",
      "988439\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to each contributor\n",
    "ar_results = data.groupby(['category', 'contributor']).apply(ar_model).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributor</th>\n",
       "      <th>category</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>pga</th>\n",
       "      <th>ctd_100</th>\n",
       "      <th>ctd_200</th>\n",
       "      <th>ctd_300</th>\n",
       "      <th>n_activities</th>\n",
       "      <th>lags</th>\n",
       "      <th>true_values</th>\n",
       "      <th>predicted_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0crat</td>\n",
       "      <td>bot</td>\n",
       "      <td>-0.667437</td>\n",
       "      <td>0.878240</td>\n",
       "      <td>1.105066</td>\n",
       "      <td>0.964117</td>\n",
       "      <td>-25</td>\n",
       "      <td>562</td>\n",
       "      <td>2170</td>\n",
       "      <td>299</td>\n",
       "      <td>[1, 12, 24, 168]</td>\n",
       "      <td>[5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1.2923226999138115, 0.8512204488572581, 0.972...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AppVeyorBot</td>\n",
       "      <td>bot</td>\n",
       "      <td>-0.014177</td>\n",
       "      <td>0.693510</td>\n",
       "      <td>0.818039</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>31</td>\n",
       "      <td>86</td>\n",
       "      <td>95</td>\n",
       "      <td>300</td>\n",
       "      <td>[1, 12, 24, 168]</td>\n",
       "      <td>[2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 2, 1, ...</td>\n",
       "      <td>[0.8093615164531129, 0.7579525565061894, 0.682...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Code-Inside-Bot</td>\n",
       "      <td>bot</td>\n",
       "      <td>0.997601</td>\n",
       "      <td>0.008013</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.839744</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>293</td>\n",
       "      <td>[1, 12, 24, 168]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1.3200161450011016e-16, 4.046242507715902e-16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CrowdinBot</td>\n",
       "      <td>bot</td>\n",
       "      <td>-0.001443</td>\n",
       "      <td>1.070054</td>\n",
       "      <td>4.638953</td>\n",
       "      <td>0.966387</td>\n",
       "      <td>-108</td>\n",
       "      <td>-311</td>\n",
       "      <td>-475</td>\n",
       "      <td>292</td>\n",
       "      <td>[1, 12, 24, 168]</td>\n",
       "      <td>[0, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[-0.01033771945395856, 0.47303370894842045, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DrahtBot</td>\n",
       "      <td>bot</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.515547</td>\n",
       "      <td>0.910024</td>\n",
       "      <td>0.800647</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-927</td>\n",
       "      <td>299</td>\n",
       "      <td>[1, 12, 24, 168]</td>\n",
       "      <td>[0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, ...</td>\n",
       "      <td>[0.3721921599465237, 0.28226559281655816, 0.41...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       contributor category        r2       mae      rmse       pga  ctd_100  \\\n",
       "0            0crat      bot -0.667437  0.878240  1.105066  0.964117      -25   \n",
       "1      AppVeyorBot      bot -0.014177  0.693510  0.818039  0.633333       31   \n",
       "2  Code-Inside-Bot      bot  0.997601  0.008013  0.105915  0.839744        0   \n",
       "3       CrowdinBot      bot -0.001443  1.070054  4.638953  0.966387     -108   \n",
       "4         DrahtBot      bot  0.001107  0.515547  0.910024  0.800647        0   \n",
       "\n",
       "   ctd_200  ctd_300  n_activities              lags  \\\n",
       "0      562     2170           299  [1, 12, 24, 168]   \n",
       "1       86       95           300  [1, 12, 24, 168]   \n",
       "2        0        0           293  [1, 12, 24, 168]   \n",
       "3     -311     -475           292  [1, 12, 24, 168]   \n",
       "4       10     -927           299  [1, 12, 24, 168]   \n",
       "\n",
       "                                         true_values  \\\n",
       "0  [5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 2, 1, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "4  [0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, ...   \n",
       "\n",
       "                                    predicted_values  \n",
       "0  [1.2923226999138115, 0.8512204488572581, 0.972...  \n",
       "1  [0.8093615164531129, 0.7579525565061894, 0.682...  \n",
       "2  [1.3200161450011016e-16, 4.046242507715902e-16...  \n",
       "3  [-0.01033771945395856, 0.47303370894842045, 0....  \n",
       "4  [0.3721921599465237, 0.28226559281655816, 0.41...  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_results.to_csv('../models-evaluation-v2/ar_model_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Seasonal Autoregressive integrated Moving-average model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarima_model(contributor):\n",
    "\n",
    "    print(contributor['contributor'].iloc[0])\n",
    "\n",
    "    # Spliting the data into training and testing sets for time series forecasting, using a time-based split with split size = 0.9\n",
    "    train, test = (\n",
    "        contributor.apply(lambda x: x[:int(0.9*len(x))]),\n",
    "        contributor.apply(lambda x: x[int(0.9*len(x)):])\n",
    "    )\n",
    "\n",
    "    # Set the frequency of the index to hourly\n",
    "    train.index.freq = 'H'\n",
    "\n",
    "    # Fit the model\n",
    "    model = SARIMAX(train['n_activities'], order=(1, 0, 1), seasonal_order=(1, 0, 1, 24), enforce_invertibility=False, enforce_stationarity=False).fit(disp=False, method='lbfgs')\n",
    "\n",
    "    # Forecast the test set using confidence interval with 95%\n",
    "    predictions = model.get_prediction(start=len(train), end=len(train)+len(test)-1).summary_frame(alpha=0.05)\n",
    "\n",
    "    # Create a series for evaluation metrics and sum of activities\n",
    "    metrics = pd.Series({\n",
    "        'contributor': contributor['contributor'].iloc[0],\n",
    "        'category': contributor['category'].iloc[0],\n",
    "        'r2': r2_score(test['n_activities'], predictions['mean']),\n",
    "        'mae': mean_absolute_error(test['n_activities'], predictions['mean']),\n",
    "        'rmse': root_mean_squared_error(test['n_activities'], predictions['mean']),\n",
    "        'pga': pga_score(test['n_activities'], predictions['mean']),\n",
    "        'pga_ci_upper': pga_score(test['n_activities'], predictions['mean_ci_upper']),\n",
    "        'n_activities': contributor['n_activities'].sum(),\n",
    "    })\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each contributor\n",
    "sarima_results = data.groupby(['category', 'contributor']).apply(sarima_model).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima_results['pga'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima_results.to_csv('../models-evaluation/sarima_model_metrics_ci.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Unobserved components model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uc_model(contributor):\n",
    "\n",
    "    print(contributor['contributor'].iloc[0])\n",
    "\n",
    "    # Spliting the data into training and testing sets for time series forecasting, using a time-based split with split size = 0.9\n",
    "    train, test = (\n",
    "        contributor.apply(lambda x: x[:int(0.9*len(x))]),\n",
    "        contributor.apply(lambda x: x[int(0.9*len(x)):])\n",
    "    )\n",
    "\n",
    "    # Set the frequency of the index to hourly\n",
    "    train.index.freq = 'H'\n",
    "\n",
    "    # Fit the model\n",
    "    model = UnobservedComponents(train['n_activities'], level=True, seasonal=24).fit(disp=False, method='lbfgs')\n",
    "\n",
    "    # Forecast the test set using confidence interval with 95%\n",
    "    predictions = model.get_prediction(start=len(train), end=len(train)+len(test)-1).summary_frame(alpha=0.05)\n",
    "\n",
    "    # Create a series for evaluation metrics and sum of activities\n",
    "    metrics = pd.Series({\n",
    "        'contributor': contributor['contributor'].iloc[0],\n",
    "        'category': contributor['category'].iloc[0],\n",
    "        'r2': r2_score(test['n_activities'], predictions['mean']),\n",
    "        'mae': mean_absolute_error(test['n_activities'], predictions['mean']),\n",
    "        'rmse': root_mean_squared_error(test['n_activities'], predictions['mean']),\n",
    "        'pga': pga_score(test['n_activities'], predictions['mean']),\n",
    "        'pga_ci_upper': pga_score(test['n_activities'], predictions['mean_ci_upper']),\n",
    "        'n_activities': contributor['n_activities'].sum(),\n",
    "    })\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each contributor\n",
    "uc_results = data.groupby(['category', 'contributor']).apply(uc_model).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc_results['rmse'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc_results.to_csv('../models-evaluation/uc_model_metrics_ci.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Holt-Winters (triple) exponential smoothing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tes_model(contributor):\n",
    "\n",
    "    print(contributor['contributor'].iloc[0])\n",
    "\n",
    "    # Spliting the data into training and testing sets for time series forecasting, using a time-based split with split size = 0.9\n",
    "    train, test = (\n",
    "        contributor.apply(lambda x: x[:int(0.9*len(x))]),\n",
    "        contributor.apply(lambda x: x[int(0.9*len(x)):])\n",
    "    )\n",
    "\n",
    "    # Set the frequency of the index to hourly\n",
    "    train.index.freq = 'H'\n",
    "\n",
    "    # Fit the model\n",
    "    try:\n",
    "        model = ETSModel(train['n_activities'], error='add', trend='add', seasonal='add', seasonal_periods=24).fit(disp=False)\n",
    "    except ValueError:\n",
    "        model = ETSModel(train['n_activities'], error='add', trend='add').fit(disp=False)\n",
    "    except:\n",
    "        print(\"Something else went wrong\")\n",
    "\n",
    "    # Forecast the test set using prediction interval with 95%\n",
    "    predictions = model.get_prediction(start=len(train), end=len(train)+len(test)-1).summary_frame(alpha=0.05)\n",
    "\n",
    "    # Create a series for evaluation metrics and sum of activities\n",
    "    metrics = pd.Series({\n",
    "        'contributor': contributor['contributor'].iloc[0],\n",
    "        'category': contributor['category'].iloc[0],\n",
    "        'r2': r2_score(test['n_activities'], predictions['mean']),\n",
    "        'mae': mean_absolute_error(test['n_activities'], predictions['mean']),\n",
    "        'rmse': root_mean_squared_error(test['n_activities'], predictions['mean']),\n",
    "        'pga': pga_score(test['n_activities'], predictions['mean']),\n",
    "        'pga_pi_upper': pga_score(test['n_activities'], predictions['pi_upper']),\n",
    "        'n_activities': contributor['n_activities'].sum()\n",
    "    })\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each contributor\n",
    "tes_results = data.groupby(['category', 'contributor']).apply(tes_model).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes_results['rmse'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes_results.to_csv('../models-evaluation/tes_model_metrics_pi.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_results = pd.read_csv('../models-evaluation/ar_model_metrics_ci.csv')\n",
    "sarima_results = pd.read_csv('../models-evaluation/sarima_model_metrics_ci.csv')\n",
    "uc_results = pd.read_csv('../models-evaluation/uc_model_metrics_ci.csv')\n",
    "tes_results = pd.read_csv('../models-evaluation/tes_model_metrics_pi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes with the given data\n",
    "data1 = ar_results[['category', 'mae', 'rmse']]\n",
    "data2 = sarima_results[['category', 'mae', 'rmse']]\n",
    "data3 = uc_results[['category', 'mae', 'rmse']]\n",
    "data4 = tes_results[['category', 'mae', 'rmse']]\n",
    "\n",
    "# melt the dataframes\n",
    "melted_data1 = pd.melt(data1, id_vars=['category'], var_name='metric', value_name='value')\n",
    "melted_data2 = pd.melt(data2, id_vars=['category'], var_name='metric', value_name='value')\n",
    "melted_data3 = pd.melt(data3, id_vars=['category'], var_name='metric', value_name='value')\n",
    "melted_data4 = pd.melt(data4, id_vars=['category'], var_name='metric', value_name='value')\n",
    "\n",
    "# create subplots\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(20, 10))\n",
    "\n",
    "# plot the boxenplots\n",
    "sns.boxenplot(ax=axs[0, 0], x='metric', y='value', hue='category', data=melted_data1, showfliers=False)\n",
    "sns.boxenplot(ax=axs[0, 1], x='metric', y='value', hue='category', data=melted_data2, showfliers=False)\n",
    "sns.boxenplot(ax=axs[1, 0], x='metric', y='value', hue='category', data=melted_data3, showfliers=False)\n",
    "sns.boxenplot(ax=axs[1, 1], x='metric', y='value', hue='category', data=melted_data4, showfliers=False)\n",
    "\n",
    "# set the titles\n",
    "axs[0, 0].set_title('AutoReg')\n",
    "axs[0, 1].set_title('SARIMA')\n",
    "axs[1, 0].set_title('UC')\n",
    "axs[1, 1].set_title('TES')\n",
    "\n",
    "# set the y-label\n",
    "axs[0, 0].set_ylabel('Median')\n",
    "axs[0, 1].set_ylabel('Median')\n",
    "axs[1, 0].set_ylabel('Median')\n",
    "axs[1, 1].set_ylabel('Median')\n",
    "\n",
    "# set the plot title\n",
    "plt.suptitle('Boxenplot of the median of MAE and RMSE')\n",
    "\n",
    "# show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes with the given data\n",
    "data1 = ar_results[['category', 'pga', 'pga_ci_upper']]\n",
    "data2 = sarima_results[['category', 'pga', 'pga_ci_upper']]\n",
    "data3 = uc_results[['category', 'pga', 'pga_ci_upper']]\n",
    "data4 = tes_results[['category', 'pga', 'pga_pi_upper']]\n",
    "\n",
    "# melt the dataframes\n",
    "melted_data1 = pd.melt(data1, id_vars=['category'], var_name='metric', value_name='value')\n",
    "melted_data2 = pd.melt(data2, id_vars=['category'], var_name='metric', value_name='value')\n",
    "melted_data3 = pd.melt(data3, id_vars=['category'], var_name='metric', value_name='value')\n",
    "melted_data4 = pd.melt(data4, id_vars=['category'], var_name='metric', value_name='value')\n",
    "\n",
    "# create subplots\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(20, 10))\n",
    "\n",
    "# plot the boxenplots\n",
    "sns.boxenplot(ax=axs[0, 0], x='metric', y='value', hue='category', data=melted_data1, showfliers=False)\n",
    "sns.boxenplot(ax=axs[0, 1], x='metric', y='value', hue='category', data=melted_data2, showfliers=False)\n",
    "sns.boxenplot(ax=axs[1, 0], x='metric', y='value', hue='category', data=melted_data3, showfliers=False)\n",
    "sns.boxenplot(ax=axs[1, 1], x='metric', y='value', hue='category', data=melted_data4, showfliers=False)\n",
    "\n",
    "# set the titles\n",
    "axs[0, 0].set_title('AutoReg')\n",
    "axs[0, 1].set_title('SARIMA')\n",
    "axs[1, 0].set_title('UC')\n",
    "axs[1, 1].set_title('TES')\n",
    "\n",
    "# set the y-label\n",
    "axs[0, 0].set_ylabel('Median')\n",
    "axs[0, 1].set_ylabel('Median')\n",
    "axs[1, 0].set_ylabel('Median')\n",
    "axs[1, 1].set_ylabel('Median')\n",
    "\n",
    "# set the plot title\n",
    "plt.suptitle('Boxenplot of the median of PGA')\n",
    "\n",
    "# show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes with the given data\n",
    "data1 = ar_results[['category', 'r2']]\n",
    "data2 = sarima_results[['category', 'r2']]\n",
    "data3 = uc_results[['category', 'r2']]\n",
    "data4 = tes_results[['category', 'r2']]\n",
    "\n",
    "# melt the dataframes\n",
    "melted_data1 = pd.melt(data1, id_vars=['category'], var_name='metric', value_name='value')\n",
    "melted_data2 = pd.melt(data2, id_vars=['category'], var_name='metric', value_name='value')\n",
    "melted_data3 = pd.melt(data3, id_vars=['category'], var_name='metric', value_name='value')\n",
    "melted_data4 = pd.melt(data4, id_vars=['category'], var_name='metric', value_name='value')\n",
    "\n",
    "# create subplots\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(20, 10))\n",
    "\n",
    "# plot the boxenplots\n",
    "sns.boxenplot(ax=axs[0, 0], x='metric', y='value', hue='category', data=melted_data1, showfliers=False)\n",
    "sns.boxenplot(ax=axs[0, 1], x='metric', y='value', hue='category', data=melted_data2, showfliers=False)\n",
    "sns.boxenplot(ax=axs[1, 0], x='metric', y='value', hue='category', data=melted_data3, showfliers=False)\n",
    "sns.boxenplot(ax=axs[1, 1], x='metric', y='value', hue='category', data=melted_data4, showfliers=False)\n",
    "\n",
    "# set the titles\n",
    "axs[0, 0].set_title('AutoReg')\n",
    "axs[0, 1].set_title('SARIMA')\n",
    "axs[1, 0].set_title('UC')\n",
    "axs[1, 1].set_title('TES')\n",
    "\n",
    "# set the y-label\n",
    "axs[0, 0].set_ylabel('Median')\n",
    "axs[0, 1].set_ylabel('Median')\n",
    "axs[1, 0].set_ylabel('Median')\n",
    "axs[1, 1].set_ylabel('Median')\n",
    "\n",
    "# set the plot title\n",
    "plt.suptitle('Boxenplot of the median of R2')\n",
    "\n",
    "# show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
