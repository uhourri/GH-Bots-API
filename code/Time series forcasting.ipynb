{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code note, I will present some time series techniques applied on activities sequences of human/bot users to predict number of activities to efficiently use Github api."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages importing & visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = pd.read_parquet('../data-raw/activities.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_by_day = (\n",
    "    activities\n",
    "    .assign(date=pd.to_datetime(activities['date']).dt.date)\n",
    "    # Grouping data by contributor and date, and counting up the activities by day\n",
    "    .groupby(['contributor', 'date'])\n",
    "    .activity\n",
    "    .count()\n",
    "    .reset_index(name='n_activities')\n",
    ")\n",
    "activities_by_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = (\n",
    "    activities_by_day[\n",
    "        activities_by_day['contributor']\n",
    "        .isin(activities_by_day\n",
    "              .groupby('contributor')['n_activities']\n",
    "              .median()\n",
    "              .nlargest(3)\n",
    "              .index\n",
    "            )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Plotting the time series\n",
    "plt.figure(figsize=(18, 8))\n",
    "sns.lineplot(x='date', y='n_activities', hue='contributor', data=temp)\n",
    "plt.title('Time Series Plot of Activity Count for Top 3 Contributors')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('# Activities')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data of the top contributor 'codeclimate[bot]' to test time series forcasting method\n",
    "temp = (\n",
    "    activities_by_day[activities_by_day['contributor'] == 'codeclimate[bot]']\n",
    "    .drop(['contributor'], axis=1)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Feature Engineering: create lag features based on the n previous dates\n",
    "n_previous_dates = 13\n",
    "for i in range(1, n_previous_dates+1):\n",
    "    temp[f'n_activities_lag_{i}'] = temp['n_activities'].shift(i)\n",
    "\n",
    "# Delete the n first rows to avoid NaN values\n",
    "temp = temp.iloc[n_previous_dates:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (last 20% of the data)\n",
    "train_size = int(len(temp) * 0.8)\n",
    "train_data, test_data = temp[:train_size], temp[train_size:]\n",
    "\n",
    "# Separate features and target variable for training\n",
    "X_train = train_data.drop(['date', 'n_activities'], axis=1)\n",
    "y_train = train_data['n_activities']\n",
    "\n",
    "# Separate features and target variable for testing\n",
    "X_test = test_data.drop(['date', 'n_activities'], axis=1)\n",
    "y_test = test_data['n_activities']\n",
    "\n",
    "# Train the time series forecasting model with multiple linear regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Mean Squared Error\n",
    "print(f'R2 Score: {r2_score(y_test, predictions)}')\n",
    "print(f'Explained variance score: {explained_variance_score(y_test, predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_r2 = 0\n",
    "max_evs = 0\n",
    "\n",
    "\n",
    "for pp in range(1, 100):\n",
    "    temp = (\n",
    "        activities_by_day[activities_by_day['contributor'] == 'codeclimate[bot]']\n",
    "        .drop(['contributor'], axis=1)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Feature Engineering: create lag features based on the n previous dates\n",
    "    n_previous_dates = pp\n",
    "    for i in range(1, n_previous_dates+1):\n",
    "        temp[f'n_activities_lag_{i}'] = temp['n_activities'].shift(i)\n",
    "\n",
    "    # Delete the n first rows to avoid NaN values\n",
    "    temp = temp.iloc[n_previous_dates:].reset_index(drop=True)\n",
    "\n",
    "    # Split the data into training and test sets (last 20% of the data)\n",
    "    train_size = int(len(temp) * 0.8)\n",
    "    train_data, test_data = temp[:train_size], temp[train_size:]\n",
    "\n",
    "    # Separate features and target variable for training\n",
    "    X_train = train_data.drop(['date', 'n_activities'], axis=1)\n",
    "    y_train = train_data['n_activities']\n",
    "\n",
    "    # Separate features and target variable for testing\n",
    "    X_test = test_data.drop(['date', 'n_activities'], axis=1)\n",
    "    y_test = test_data['n_activities']\n",
    "\n",
    "    # Train the time series forecasting model with multiple linear regression\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    if(max_r2 < r2_score(y_test, predictions)):\n",
    "        max_r2 = r2_score(y_test, predictions)\n",
    "        i_evs = n_previous_dates\n",
    "        print(f'[R2] New score found with n = {n_previous_dates}, R2 Score: {r2_score(y_test, predictions)}, Explained variance score: {explained_variance_score(y_test, predictions)}')\n",
    "\n",
    "    if(max_evs < explained_variance_score(y_test, predictions)):\n",
    "        max_evs = explained_variance_score(y_test, predictions)\n",
    "        i_evs = n_previous_dates\n",
    "        print(f'[EVS] New score found with n = {n_previous_dates}, R2 Score: {r2_score(y_test, predictions)}, Explained variance score: {explained_variance_score(y_test, predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_r2, max_evs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Results\n",
    "plt.figure(figsize=(18, 10))\n",
    "sns.lineplot(x=temp['date'], y=temp['n_activities'], label='Real Values')\n",
    "sns.lineplot(x=test_data['date'], y=predictions, label='Predicted Values')\n",
    "plt.title('Time Series Forecasting - Real vs Predicted Values')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Activities')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
