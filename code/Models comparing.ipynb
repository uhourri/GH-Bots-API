{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will compare between difference forcasting models, starting from simple linear to arima models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import AutoRegressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = pd.read_parquet('../data-raw/activities.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We forecast involves using the previous observations (same date, same time) to predict the next time step (one week for train and w=one for test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_by_time = (\n",
    "    # extract data just for 2 weeks\n",
    "    activities[(activities['date'] >= '2023-02-01 00:00:00+00:00') & (activities['date'] < '2023-02-15 00:00:00+00:00')]\n",
    "    .assign(datetime=activities['date'].dt.strftime('%Y-%m-%d %H:00:00'))\n",
    "    .groupby(['contributor', 'category', 'datetime'])\n",
    "    .activity.count()\n",
    "    .unstack(fill_value=0).stack()\n",
    "    .reset_index(name='n_activities')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities[(activities['date'] >= '2022-02-01 00:00:00+00:00') & (activities['date'] < '2022-02-15 00:00:00+00:00')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_by_time.head(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_activities = activities_by_time[activities_by_time['datetime'] < '2023-02-08 00:00:00'].reset_index(drop=True)\n",
    "test_activities = activities_by_time[activities_by_time['datetime'] >= '2023-02-08 00:00:00'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_activities), len(test_activities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_activities['p_activities'] = train_activities['n_activities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_activities.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(actual, predicted):\n",
    "    r2 = r2_score(actual, predicted)\n",
    "    mae = mean_absolute_error(actual, predicted) \n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    sum_n_activities = actual.sum()\n",
    "    return pd.Series({'r2': r2, 'mae': mae, 'mse': mse, 'n_activities':sum_n_activities})\n",
    "\n",
    "# Group by contributor and calculate metrics\n",
    "result = test_activities.groupby(['contributor', 'category']).apply(lambda x: calculate_metrics(x['n_activities'], x['p_activities'])).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values(by='r2', ascending=False).head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('../eval/naive_model_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_by_time = (\n",
    "    activities\n",
    "    .assign(datetime=activities['date'].dt.strftime('%Y-%m-%d %H:00:00'))\n",
    "    .groupby(['contributor', 'category', 'datetime'])\n",
    "    .activity.count()\n",
    "    .unstack(fill_value=0).stack()\n",
    "    .reset_index(name='n_activities')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_by_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create lag features\n",
    "def create_lag_features(group):\n",
    "    n_previous_times = 168\n",
    "    for i in range(1, n_previous_times + 1):\n",
    "        group[f'n_activities_lag_{i}'] = group['n_activities'].shift(i)\n",
    "    return group.iloc[n_previous_times:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to each group\n",
    "laged_activities = activities_by_time.groupby(['contributor', 'category']).apply(create_lag_features).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laged_activities[['contributor','category','datetime','n_activities','n_activities_lag_1','n_activities_lag_2','n_activities_lag_3']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the model and return metrics for each contributor\n",
    "def evaluate_metrics(group_data):\n",
    "    train_data = group_data[group_data['datetime'] < '2023-04-01 00:00:00'].reset_index(drop=True)\n",
    "    test_data = group_data[group_data['datetime'] >= '2023-04-01 00:00:00'].reset_index(drop=True)\n",
    "\n",
    "    # Separate features and target variable\n",
    "    X_train = train_data.drop(['contributor', 'category', 'datetime', 'n_activities'], axis=1)\n",
    "    y_train = train_data['n_activities']\n",
    "\n",
    "    X_test = test_data.drop(['contributor', 'category', 'datetime', 'n_activities'], axis=1)\n",
    "    y_test = test_data['n_activities']\n",
    "\n",
    "    # Train the time series forecasting model with multiple linear regression\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "\n",
    "    # Create a DataFrame for evaluation metrics and sum of activities\n",
    "    evaluation_metrics = pd.Series({\n",
    "        'contributor': group_data['contributor'].iloc[0],  # Use the first value since it's the same for the group\n",
    "        'category': group_data['category'].iloc[0],  # Use the first value since it's the same for the group\n",
    "        'r2': r2,\n",
    "        'mae': mae,\n",
    "        'mse': mse,\n",
    "        'n_activities': test_data['n_activities'].sum()\n",
    "    })\n",
    "\n",
    "    return evaluation_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each group and concatenate the results\n",
    "result = laged_activities.groupby(['contributor', 'category']).apply(evaluate_metrics).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values(by='r2', ascending=False).head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('../eval/reg_model_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoregression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_by_time = (\n",
    "    activities\n",
    "    .assign(datetime=activities['date'].dt.strftime('%Y-%m-%d %H:00:00'))\n",
    "    .groupby(['contributor', 'category', 'datetime'])\n",
    "    .activity.count()\n",
    "    .unstack(fill_value=0).stack()\n",
    "    .reset_index(name='n_activities')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_by_time.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data of the top contributor 'sourcegraph-bot, codeclimate[bot]' to test time series decomposition method\n",
    "temp = (\n",
    "    activities_by_time.groupby(['contributor', 'category']).get_group(('codeclimate[bot]','bot'))\n",
    "    .drop(['contributor', 'category'], axis=1)\n",
    "    .reset_index(drop=True)\n",
    "    .fillna(0)\n",
    ")\n",
    "temp[\"datetime\"] = pd.to_datetime(temp[\"datetime\"])\n",
    "\n",
    "# Statsforecast specifications\n",
    "temp[\"unique_id\"]=\"1\"\n",
    "temp.columns=[\"ds\", \"y\", \"unique_id\"]\n",
    "#temp.tail(10)\n",
    "\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = temp[temp['ds'] < '2023-04-01 00:00:00'].reset_index(drop=True)\n",
    "test_data = temp[temp['ds'] >= '2023-04-01 00:00:00'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = StatsForecast(df=train_data,\n",
    "                   models=[AutoRegressive(lags=[168], include_mean=True)],\n",
    "                   freq='H', \n",
    "                   n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = sf.forecast(h=len(test_data), level=[95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoregression model (statsmodels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_by_time = (\n",
    "    activities\n",
    "    .assign(datetime=activities['date'].dt.strftime('%Y-%m-%d %H:00:00'))\n",
    "    .groupby(['contributor', 'category', 'datetime'])\n",
    "    .activity.count()\n",
    "    .unstack(fill_value=0).stack()\n",
    "    .reset_index(name='n_activities')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency H will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 6.000939191936709\n",
      "MSE: 59.76924752042606\n",
      "R2: 0.36775160785070204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/statsmodels/tsa/deterministic.py:302: UserWarning: Only PeriodIndexes, DatetimeIndexes with a frequency set, RangesIndexes, and Index with a unit increment support extending. The index is set will contain the position relative to the data length.\n",
      "  fcast_index = self._extend_index(index, steps, forecast_index)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/statsmodels/tsa/deterministic.py:435: UserWarning: Only PeriodIndexes, DatetimeIndexes with a frequency set, RangesIndexes, and Index with a unit increment support extending. The index is set will contain the position relative to the data length.\n",
      "  fcast_index = self._extend_index(index, steps, forecast_index)\n"
     ]
    }
   ],
   "source": [
    "# Get the data of the top contributor 'sourcegraph-bot' to test time series decomposition method\n",
    "temp = (\n",
    "    activities_by_time.groupby(['contributor', 'category']).get_group(('codeclimate[bot]','bot'))\n",
    "    .drop(['contributor', 'category'], axis=1)\n",
    "    .reset_index(drop=True)\n",
    "    .set_index('datetime', drop=True)\n",
    "    .fillna(0)\n",
    ")\n",
    "temp.index.name = None\n",
    "\n",
    "train = temp.loc[:'2023-03-31 23:00:00']\n",
    "test = temp.loc['2023-04-01 00:00:00':]\n",
    "\n",
    "model = AutoReg(train['n_activities'], lags=24*7, seasonal=True, period=24*7)\n",
    "result = model.fit()\n",
    "\n",
    "predictions = result.predict(start=len(train), end=len(train) + len(test) - 1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "actual_values = test['n_activities']\n",
    "mae = mean_absolute_error(actual_values, predictions)\n",
    "mse = mean_squared_error(actual_values, predictions)\n",
    "r2 = r2_score(actual_values, predictions)\n",
    "\n",
    "# Display the results\n",
    "print(f'MAE: {mae}')\n",
    "print(f'MSE: {mse}')\n",
    "print(f'R2: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, predict and evaluate\n",
    "def auro_reg_model(group_data):\n",
    "    train_data = group_data[group_data['datetime'] < '2023-04-01 00:00:00'].reset_index(drop=True)\n",
    "    test_data = group_data[group_data['datetime'] >= '2023-04-01 00:00:00'].reset_index(drop=True)\n",
    "\n",
    "    # Separate features and target variable\n",
    "    X_train = train_data.drop(['contributor', 'category', 'datetime', 'n_activities'], axis=1)\n",
    "    y_train = train_data['n_activities']\n",
    "\n",
    "    X_test = test_data.drop(['contributor', 'category', 'datetime', 'n_activities'], axis=1)\n",
    "    y_test = test_data['n_activities']\n",
    "\n",
    "    # Train the time series forecasting model with multiple linear regression\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "\n",
    "    # Create a DataFrame for evaluation metrics and sum of activities\n",
    "    evaluation_metrics = pd.Series({\n",
    "        'contributor': group_data['contributor'].iloc[0],  # Use the first value since it's the same for the group\n",
    "        'category': group_data['category'].iloc[0],  # Use the first value since it's the same for the group\n",
    "        'r2': r2,\n",
    "        'mae': mae,\n",
    "        'mse': mse,\n",
    "        'n_activities': test_data['n_activities'].sum()\n",
    "    })\n",
    "\n",
    "    return evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each group and concatenate the results\n",
    "result = laged_activities.groupby(['contributor', 'category']).apply(auro_reg_model).reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
